---
title: "Machine learning (1)"
author: "Guyliann Engels & Philippe Grosjean"
description: "**SDD III Module 1** Découverte de la classification supervisée avec l'ADL."
tutorial:
  id: "C01Lb_ml1"
  version: 2.1.0/7
output:
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
BioDataScience3::learnr_setup()
SciViews::R()
library(mlearning)
library(rsample)

# exercice preparation --------
read("biometry", package = "BioDataScience") %>.%
  select(., gender, weight, height, wrist) %>.%
  drop_na(.) %->%
  bio

## Prepare train et test sets
set.seed(164)
bio_split <- initial_split(bio, prop = 2/3)
bio_train <- training(bio_split)
bio_test <- testing(bio_split)

#n <- nrow(bio)
#n_train <- round(n * 2/3)
#set.seed(164)
#train <- sample(1:n, n_train)
#bio_train <- bio[ train, ]
#bio_test <- bio[ -train, ]

## Creation d'un modèle lda
bio_lda <- mlLda(data = bio_train, gender ~ .)

## Confusion 
bio_conf <- confusion(predict(bio_lda, bio_test), bio_test$gender)
conf_tab <- summary(bio_conf)
```

```{r, echo=FALSE}
BioDataScience3::learnr_banner()
```

```{r, context="server"}
BioDataScience3::learnr_server(input, output, session)
```

```{r}
as.prcomp <- function(x, ...)
  UseMethod("as.prcomp")

as.prcomp.default <- function(x, ...)
  stop("No method to convert this object into a 'prcomp'")

as.prcomp.prcomp <- function(x, ...)
  x

as.prcomp.princomp <- function(x, ...)
  structure(list(sdev = as.numeric(x$sdev), rotation = unclass(x$loadings),
    center = x$center, scale = x$scale, x = as.matrix(x$scores)),
    class = "prcomp")

# Comparison of pcomp() -> as.prcomp() with prcomp() directly
# Almost the same, only no rownames for x (is it important?)
#iris_prcomp_pcomp <- as.prcomp(pcomp(iris[, -5], scale = TRUE))
#iris_prcomp <- prcomp(iris[, -5], scale = TRUE)

# Now, broom methods can be defined simply by converting into prcomp objects
augment.princomp <- function(x, data = NULL, newdata, ...)
  if (missing(newdata)) {
  augment(as.prcomp(x), data = data, ...)
  } else {
    augment(as.prcomp(x), data = data, newdata = newdata, ...)
  }

tidy.princomp <- function(x, matrix = "u", ...)
  tidy(as.prcomp(x), matrix = matrix, ...)

# There is no glance.prcomp() method

# There is a problem with pcomp() that returns a data.frame in scores,
# while it is a matrix in the original princomp object. pca() corrects this
pca <- function(x, ...) {
  res <- SciViews::pcomp(x, ...)
  # Change scores into a matrix
  res$scores <- as.matrix(res$scores)
  res
}

scale_axes <- function(data, aspect.ratio = 1) {
  range_x <- range(data[, 1])
  span_x <- abs(max(range_x) - min(range_x))
  range_y <- range(data[, 2])
  span_y <- abs(max(range_y) - min(range_y))
  if ((span_y / aspect.ratio) > span_x) {
    # Adjust range_x
    span_x_2 <- span_y / aspect.ratio / 2
    range_x_mid <- sum(range_x) / 2
    range_x <- c(range_x_mid - span_x_2, range_x_mid + span_x_2)
  } else {
    # Adjust range_y
    span_y_2 <- span_x * aspect.ratio / 2
    range_y_mid <- sum(range_y) / 2
    range_y <- c(range_y_mid - span_y_2, range_y_mid + span_y_2)
  }
  list(x = range_x, y = range_y)
}

autoplot.pcomp <- function(object,
type = c("screeplot", "altscreeplot", "loadings", "correlations", "scores", "biplot"),
choices = 1L:2L, name = deparse(substitute(object)), ar.length = 0.1,
circle.col = "gray", col = "black", fill = "gray", scale = 1, aspect.ratio = 1,
repel = FALSE, labels, title, xlab, ylab, ...) {
  type = match.arg(type)

  if (missing(title))
    title <- paste(name, type, sep = " - ")

  contribs <- paste0(names(object$sdev), " (",
    round((object$sdev^2/object$totdev^2) * 100, digits = 1), "%)")[choices]

  scores <- as.data.frame(object$scores[, choices])
  names(scores) <- c("x", "y")
  if (!missing(labels)) {
    if (length(labels) != nrow(scores))
      stop("You must provide a character vector of length ", nrow(scores),
        " for 'labels'")
    scores$labels <- labels
  } else {# Default labels are row numbers
    scores$labels <- 1:nrow(scores)
  }

  lims <- scale_axes(scores, aspect.ratio = aspect.ratio)

  if (!missing(col)) {
    if (length(col) != nrow(scores))
      stop("You must provide a vector of length ", nrow(scores), " for 'col'")
    scores$color <- col
    scores_formula <- y ~ x %col=% color %label=% labels
  } else {
    if (missing(labels)) {
      scores_formula <- y ~ x %label=% labels
    } else {
      scores_formula <- y ~ x %col=% labels %label=% labels
    }
  }

  res <- switch(type,
    screeplot = object %>.% # Classical screeplot
      tidy(., "pcs") %>.%
      chart(data = ., std.dev^2 ~ PC) +
      geom_col(col = col, fill = fill) +
      labs(y = "Variances", title = title),

    altscreeplot = object %>.% # screeplot represented by dots and lines
      tidy(., "pcs") %>.%
      chart(data = ., std.dev^2 ~ PC) +
      geom_line(col = col) +
      geom_point(col = "white", fill = col, size = 2, shape = 21, stroke = 3) +
      labs(y = "Variances", title = title),

    loadings = object %>.% # Plots of the variables
      tidy(., "variables") %>.%
      spread(., key = PC, value = value) %>.%
      #rename_if(., is.numeric, function(x) paste0("PC", x)) %>.%
      select(., c(1, choices + 1)) %>.%
      set_names(., c("labels", "x", "y")) %>.%
      chart(data = ., y ~ x %xend=% 0 %yend=% 0 %label=% labels) +
        annotate("path", col = circle.col,
          x = cos(seq(0, 2*pi, length.out = 100)),
          y = sin(seq(0, 2*pi, length.out = 100))) +
        geom_hline(yintercept = 0, col = circle.col) +
        geom_vline(xintercept = 0, col = circle.col) +
        geom_segment(arrow = arrow(length = unit(ar.length, "inches"),
          ends = "first")) +
        ggrepel::geom_text_repel(hjust = "outward", vjust = "outward") +
        coord_fixed(ratio = 1) +
        labs(x = contribs[1], y = contribs[2], title = title),

    correlations = object %>.% # Correlations plot
      Correlation(.) %>.%
      as_tibble(., rownames = "labels") %>.%
      select(., c(1, choices + 1)) %>.%
      set_names(., c("labels", "x", "y")) %>.%
      chart(data = ., y ~ x %xend=% 0 %yend=% 0 %label=% labels) +
      annotate("path", col = circle.col,
        x = cos(seq(0, 2*pi, length.out = 100)),
        y = sin(seq(0, 2*pi, length.out = 100))) +
      geom_hline(yintercept = 0, col = circle.col) +
      geom_vline(xintercept = 0, col = circle.col) +
      geom_segment(arrow = arrow(length = unit(ar.length, "inches"),
        ends = "first")) +
      ggrepel::geom_text_repel(hjust = "outward", vjust = "outward") +
      coord_fixed(ratio = 1) +
      labs(x = contribs[1], y = contribs[2], title = title),

    scores = scores %>.% # Plot of the individuals
      chart(data = ., scores_formula) +
      geom_hline(yintercept = 0, col = circle.col) +
      geom_vline(xintercept = 0, col = circle.col) +
      coord_fixed(ratio = 1, xlim = lims$x, ylim = lims$y, expand = TRUE) +
      labs(x = contribs[1], y = contribs[2], title = title) +
      theme(legend.position = "none"),

    biplot = object %>.% # Biplot using ggfortify function
      as.prcomp(.) %>.%
      ggfortify:::autoplot.prcomp(., x = choices[1], y = choices[2],
        scale = scale, size = -1, label = TRUE, loadings = TRUE,
        loadings.label = TRUE) +
      geom_hline(yintercept = 0, col = circle.col) +
      geom_vline(xintercept = 0, col = circle.col) +
      theme_sciviews() +
      labs(x = contribs[1], y = contribs[2], title = title),

    stop("Unrecognized type, must be 'screeplot', 'altscreeplot', loadings', 'correlations', 'scores' or 'biplot'")
  )

  if (type == "scores") {
    if (isTRUE(repel)) {
      res <- res + geom_point() + ggrepel::geom_text_repel()
    } else {# Use text
      res <- res + geom_text()
    }
  }

  if (!missing(xlab))
    res <- res + xlab(xlab)
  if (!missing(ylab))
    res <- res + ylab(ylab)
  res
}

chart.pcomp <- function(data, choices = 1L:2L, name = deparse(substitute(data)),
..., type = NULL, env = parent.frame())
  autoplot.pcomp(data, choices = choices, name = name, ..., type = type, env = env)
class(chart.pcomp) <- c("function", "subsettable_type")
```

------------------------------------------------------------------------

## Objectifs

De très nombreux algorithmes de classifications supervisées existent, la méthode liée à cette séance d'exercice porte sur l'analyse discriminante linéaire. Cette méthode se base sur les mêmes principes que l'analyse discriminante linéaire.

La mise en place d'un classifieur requiert de suivre une série d'étapes :

-   explorer les données
    -   visualiser vos données à l'aide de plusieurs graphiques,
    -   vérifier et corriger le type de chaque variable (surtout pour les variables facteurs),
    -   calculer des variables supplémentaires pertinentes,
    -   traiter le problème des valeurs manquantes si votre modèle ne les gère pas,
    -   éliminer les variables inutiles (par exemple, le code d'identification d'un individu).
-   préparer le set d'apprentissage et le set de test
-   entrainer un classifieur (choisir l'algorithme, l'entrainer...)
-   évaluer la qualité du classifieur à l'aide de métrique pertinente.
-   déployer le classifieur afin de prédire les classes d'intérêts

L'objectif de ce tutoriel est de vous permettre de découvrir l'analyse discriminante linéaire.Vous devez être bien conscient de toutes les étapes ci-dessus. Cependant ici, nous allons aller droit au but et considérer que cela a été fait en partie pour vous, mais ne l'oubliez pas plus tard dans vos projets !

## Différenciation des hommes et des femmes

Proposez un classifieur qui permet de discriminer les hommes des femmes sur base de mesures biométriques

![](images/man_woman.png){width="35%"}

Vous avez à votre disposition le tableau de données suivant :

```{r, echo = TRUE}
read("biometry", package = "BioDataScience",lang = "fr") %>.%
  sselect(., gender, weight, height, wrist) ->
  bio
```

Ce jeu de données est constitué`r nrow(bio)` d'individus. Quatre variables sont sélectionnées pour cette étude `r names(bio)`. Notre variable d'intérêt est la variable `gender` . Cette variable a deux niveaux : `M` (Man), `W` (Woman). Il y a également trois variables numériques qui sont les attributs à utiliser pour la mise en place du classifieur :

-   weight : la masse en kg
-   height : la taille en cm
-   wrist : la circonférence du poignet en mm

La première étape est d'explorer ce tableau de données à l'aide de tableau, de graphiques, d'analyses multivariées

```{r, echo = TRUE}
skimr::skim(bio)
```

Étant donné que la LDA se base sur les mêmes principes que l'ACP, une ACP est réalisée ci-dessous afin d'explorer les données.

```{r}
bio_red <- na_omit(bio)
bio_pca <- pca(data = sselect(bio, -gender), ~., scale = TRUE)
summary(bio_pca)
a <- chart(bio_pca, type = "loadings")
b <- chart(bio_pca, type = "scores", labels = bio_red$gender) +
  stat_ellipse()
combine_charts(list(a,b))
```

```{r qu_explo}
question("Sélectionnez les éléments pertinents de l'analyse exploratoire proposée ci-dessus.",
  answer("Le tableau de données comprend 4 variables numériques et une variable facteur ordonnée."),
  answer("La répartition entre les hommes (M) et les femmes (W) est proche de 50/50", correct = TRUE),
  answer("On observe la présence de valeurs manquantes pour la variable de la circomférence du poignets.", correct = TRUE),
  answer("Toutes les variables sont complètes. Il n'y a pas de valeurs manquantes dans ce tableau."),
  answer("L'ACP permet de séparer assez efficacement les hommes des femmes. Les hommes ont tendance à être plus grands et plus lourds.", correct = TRUE),
  allow_retry = TRUE, random_answer_order = TRUE,
  correct = "Bravo ! Vous avez sélectionné les éléments correctes.",
  incorrect = "Attention, Ce n'est pas complet. Intéressez vous avec attention à la description du tableau et à l'ACP",
  submit_button = "Soumettre une réponse",
  try_again_button = "Resoumettre une réponse")
```

## Préparation des données

Suite à la phase exploratoire de l'analyse, il en est ressorti que des valeurs manquantes devaient être filtrées.

```{r, echo = TRUE}
bio <- na_omit(bio, "wrist") # Filtrer les valeurs manquantes en spécifiant la colonne d'intérêt.
```

Utilisez les fonctions `initial_split()`, `training()` et `testing()` du package `rsamples` afin de définir votre set d'apprentissage et votre set de test. Votre set d'apprentissage se nomme `bio_train` et votre set de test se nomme `bio_test`. Il vous est demandé de réaliser un set d'entrainement contenant 0.75 des observations.

```{r split_h2, exercise = TRUE}
set.seed(164) # Fixer le début du générateur de nombres pseudo-aléatoires
bio_split <- initial_split(___, prop = ___)
bio_split
# Diviser le tableau
___ <- training(___)
bio_test <- testing(___)
```

```{r split_h2-hint-1}
set.seed(164) # Fixer le début du générateur de nombres pseudo-aléatoires
bio_split <- initial_split(bio, prop = 0.75)
bio_split
# Diviser le tableau
___ <- training(___)
bio_test <- testing(___)

## Attention, le prochain indice est la solution ##
```

```{r split_h2-solution}
set.seed(164) # Fixer le début du générateur de nombres pseudo-aléatoires
bio_split <- initial_split(bio, prop = 0.75)
bio_split
# Diviser le tableau
bio_train <- training(bio_split)
bio_test <- testing(bio_split)
```

```{r split_h2-check}
grade_code("Parfait ! Vous avez réalisez votre set d'apprentissage et votre set d'évaluation avec les proportions demandées. N'hésitez pas à consulter la page d'aide des fonctions initial_split(), training() et test(). Vous trouverez des informations très intéressantes sur la réalisation des sets d'apprentissage et de test.", "Avez vous bien respectée les consignes ? Il ne faut compléter que les éléments signalés par ___.")
```

## Entrainement du modèle

Il vous est demandé de réaliser un classifieur utilisant l'analyse discriminante linéaire. C'est à vous de définir le tableau de données à employer entre `bio`, `bio_train` et `bio_test`.

Entrainez un modèle de type discriminant linéaire avec le set d'apprentissage. Votre objectif est de prédire la variable `gender` à l'aide des trois variables numériques. Placer ce classifieur dans la variable `bio_lda`.

```{r lda1_h2, exercise = TRUE}
bio_lda <- mlLda(data = ___, ___ ~ ___)
summary(bio_lda)
```

```{r lda1_h2-hint-1}
bio_lda <- mlLda(data = bio_train, ___ ~ ___)
summary(bio_lda)

## Attention, le prochain indice est la solution ##
```

```{r lda1_h2-solution}
## Solution ##
bio_lda <- mlLda(data = bio_train, gender ~ .)
summary(bio_lda)
```

```{r lda1_h2-check}
grade_code("Votre premier modèle LDA. Voyons quoi en faire à présent...", "Avez vous bien proposé la formule écrites sous sa forme condensée ? ")
```

*La formule doit être écrite sous sa forme condensée*

## Performance de votre modèle

Vous devez maintenant tester les performances de votre classifieur `bio_lda`. Ne vous trompez pas dans le jeu de données à utiliser `bio_train` ou `bio_test` pour ce faire.

```{r lda2_h2, exercise = TRUE}
bio_pred <- predict(___, ___)
bio_conf <- confusion(___, ___$___)
bio_conf
summary(bio_conf)
```

```{r lda2_h2-hint-1}
bio_pred <- predict(bio_lda, bio_test)
bio_conf <- confusion(bio_pred, ___$___)
bio_conf
summary(bio_conf)

## Attention, le prochain indice est la solution ##
```

```{r lda2_h2-solution}
## Solution ##
bio_pred <- predict(bio_lda, bio_test)
bio_conf <- confusion(bio_pred, bio_test$gender)
bio_conf
summary(bio_conf)
```

```{r lda2_h2-check}
grade_code("Vous venez de réaliser vos premières analyses des performances d'un classifieur. Prenez un peu de temps pour analyser votre matrice de confusion et les métriques qui en découlent et répondez aux questions suivantes.")
```

```{r qu_lda}
quiz(
  question("Combien d'items du set de test sont correctement classé ?",
    answer(sprintf("%1.f", sum(conf_tab$TP)), correct = TRUE),
    answer(sprintf("%1.f", sum(conf_tab$Auto))),
    answer(sprintf("%1.f", conf_tab$Manu[1])),
    answer(sprintf("%1.f", conf_tab$TN[2])),
    answer("Aucune des réponses proposées"),
    allow_retry = TRUE, random_answer_order = TRUE,
    submit_button = "Soumettre une réponse",
    try_again_button = "Resoumettre une réponse",
    incorrect = "Mauvaise réponse. Recommencez afin de trouver la bonne réponse",
    correct = "Bravo, c'est correct !"),
  question("Quel est le taux d'erreur global (en %) ?",
    answer(sprintf("%.1f", 100 * (1 - (sum(conf_tab$TP)/sum(conf_tab$Auto)))), correct = TRUE),
    answer(sprintf("%.1f", 100 * (sum(conf_tab$TP)/sum(conf_tab$Auto)))),
  answer(sprintf("%3.f", sum(conf_tab$Auto) - sum(conf_tab$TP))),
    answer(sprintf("%3.f", conf_tab$TN[2])),
    answer("Aucune des réponses proposées"),
    allow_retry = TRUE, random_answer_order = TRUE,
    submit_button = "Soumettre une réponse",
    try_again_button = "Resoumettre une réponse",
    incorrect = "Mauvaise réponse. Recommencez afin de trouver la bonne réponse",
    correct = "Bravo, c'est correct !"),
  question("Quel est le taux de vrai positif pour les hommes (M) ?",
    answer(sprintf("%.3f", conf_tab[row.names(conf_tab) == "M", ]$Recall), correct = TRUE),
    answer(sprintf("%.3f", conf_tab[row.names(conf_tab) == "M", ]$Fscore)),
    answer(sprintf("%3.f", sum(conf_tab$Auto) - sum(conf_tab$TP))),
    answer(sprintf("%.3f", conf_tab[row.names(conf_tab) == "W", ]$Recall)),
    answer("Aucune des réponses proposées"),
    allow_retry = TRUE, random_answer_order = TRUE,
    submit_button = "Soumettre une réponse",
    try_again_button = "Resoumettre une réponse",
    incorrect = "Mauvaise réponse. Recommencez afin de trouver la bonne réponse",
    correct = "Bravo, c'est correct !")
  )
```

## Conclusion

Bien joué ! Vous venez de proposer votre premier classifieur. Vous avez réalisé les étapes d'exploration des données, de création de votre modèle et de l'évaluation de votre modèle. Ce modèle est prêt pour être employé sur de nouvelles observations.

```{r comm_noscore, echo=FALSE}
question_text(
  "Laissez-nous vos impressions sur cet outil pédagogique",
  answer("", TRUE, message = "Pas de commentaires... C'est bien aussi."),
  incorrect = "Vos commentaires sont enregistrés.",
  placeholder = "Entrez vos commentaires ici...",
  allow_retry = TRUE
)
```
