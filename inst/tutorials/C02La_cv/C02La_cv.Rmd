---
title: "Validation croisée"
author: "Guyliann Engels & Philippe Grosjean"
description: "**SDD III Module 2** Utilisation de la validation croisée sur une ADL."
tutorial:
  id: "C02La_cv"
  version: 2.1.0/8
output:
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
BioDataScience3::learnr_setup()
SciViews::R("explore", "ml", lang = "fr")

# Import dataset ----
rice <- read("rice", package = "BioDataScience3", lang = "fr")
# genrateur de nombre pseudo aléatoire
set.seed(8888)
# Training and test set ----
rice_split <- rsample::initial_split(rice, 0.8, strata = class)
rice_train <- rsample::training(rice_split)
rice_test <- rsample::testing(rice_split)
# mlda
rice_lda <- mlLda(data = rice_train, class ~ .)
rice_conf <- confusion(predict(rice_lda, rice_test), rice_test$class)
rice_tab <- summary(rice_conf)
# mlda with cv 10 times
rice_lda_cv <- mlLda(data = rice, class ~ .)
rice_conf_cv <- confusion(cvpredict(rice_lda_cv, cv.k = 10), rice$class)
rice_tab_cv <- summary(rice_conf_cv)
```

```{r, echo=FALSE}
BioDataScience3::learnr_banner()
```

```{r, context="server"}
BioDataScience3::learnr_server(input, output, session)
```

------------------------------------------------------------------------

## Objectifs

Lors de la création d'un classifieur, on va définir un set d'apprentissage et un set de test. Il est évident qu'il ne faut jamais employer les mêmes individus en apprentissage et en test. Cela aurait pour conséquence de surévaluer la capacité d'un classifieur à reconnaitre les niveaux de la variable facteur d'intérêt.

La validation croisée est une méthode particulière qui permet d'employer tous les objets, à la fois dans le set d'apprentissage et dans le set de test, mais jamais simultanément.

L'objectif de ce tutoriel est de comprendre la validation croisée et de l'appliquer en pratique dans le cas d'une analyse discriminante linéaire.

## Exploration des données

Les données employées dans cette séance d'exercice sont associées à l'article : ["Classification of Rice Varieties Using Artificial Intelligence Methods"](https://doi.org/10.18201/ijisae.2019355381). N'hésitez pas à consulter cet article pour en apprendre davantage sur ces données.

```{r, echo=TRUE}
rice <- read("rice", package = "BioDataScience3")
```

Le tableau `rice` comprend `r nrow(rice)` observations. Deux espèces de riz sont étudiées : `Cammeo` et `Osmancik`. Sur base d'analyse d'image, sept variables morphologiques sont extraites comme le périmètre, l'aire ou encore la longueur de l'axe majeur.

Les résultats ci-dessous vous renseignent sur les variables.

```{r, echo = TRUE}
skimr::skim(rice)
```

Étant donné que vous allez employer l'analyse discriminante linéaire afin d'entrainer vos classifieurs. Une ACP est réalisée ci-dessous vu que ces deux méthodes se basent sur les mêmes principes.

```{r, echo=TRUE}
rice_pca <- pca(data = sselect(rice, -class), ~., scale = TRUE)
summary(rice_pca)
```

Le graphique des éboulis est proposé ci-dessous

```{r, echo=TRUE}
chart(rice_pca, type = "scree")
```

La représentation dans l'espace des variables est proposée ci-dessous

```{r, echo=TRUE}
chart(rice_pca, type = "loadings")
```

La représentation dans l'espace des individus est proposée ci-dessous

```{r, echo=TRUE}
chart(rice_pca, type = "scores", labels = rice$class)
```

L'exploration des données a été réalisée pour vous. Avant de passer à la section suivante, explorer les tableaux et les graphiques proposés ci-dessus.

## Préparation du set d'apprentissage et de test

Utilisez les fonctions `initial_split()`, `training()` et `testing()` du package `rsamples` afin de définir votre set d'apprentissage et votre set de test. Votre set d'apprentissage se nomme `rice_train` et votre set de test se nomme `rice_test`. Il vous est demandé de réaliser un set d'entrainement contenant 0.8 des observations. Cet échantillonnage doit être stratifié grâce à la variable `class`.

```{r rice_split_h2, exercise = TRUE}
set.seed(8888) # Fixer le début du générateur de nombres pseudo-aléatoires
rice_split <- initial_split(___, prop = ___, strata = ___)
rice_split
# Diviser le tableau
___ <- training(___)
rice_test <- testing(___)
```

```{r rice_split_h2-hint-1}
set.seed(8888) # Fixer le début du générateur de nombres pseudo-aléatoires
rice_split <- initial_split(rice, prop = 0.8, strata = ___)
rice_split
# Diviser le tableau
___ <- training(___)
rice_test <- testing(___)

## Attention, le prochain indice est la solution ##
```

```{r rice_split_h2-solution}
set.seed(8888) # Fixer le début du générateur de nombres pseudo-aléatoires
rice_split <- initial_split(rice, prop = 0.8, strata = class)
rice_split
# Diviser le tableau
rice_train <- training(rice_split)
rice_test <- testing(rice_split)
```

```{r rice_split_h2-check}
grade_code("Parfait ! Vous avez réalisez votre set d'apprentissage et votre set d'évaluation avec les proportions demandées.", "Avez vous bien respectée les consignes ? Il ne faut compléter que les éléments signalés par ___.")
```

## Création des classifieurs

### Analyse discriminante linéaire

Il vous est demandé de réaliser un classifieur utilisant l'analyse discriminante linéaire. C'est à vous de définir le tableau de données à employer entre `rice`, `rice_train` et `rice_test`.

Entrainez un modèle de type analyse discriminant linéaire avec le set d'apprentissage. Votre objectif est de prédire la variable `class` à l'aide des sept variable. Assignez le classifieur n'utilisant pas la validation croisée à `rice_lda` et assignez le classifieur utilisant la validation croisée à rice_cv_lda.

```{r lda_h2, exercise = TRUE}
set.seed(8888)
rice_lda <- mlLda(data = ___, ___ ~ ___)
summary(rice_lda)
```

```{r lda_h2-hint-1}
set.seed(8888)
rice_lda <- mlLda(data = rice_train, ___ ~ ___)
summary(rice_lda)

## Attention, le prochain indice est la solution ##
```

```{r lda_h2-solution}
## Solution ##
set.seed(8888)
rice_lda <- mlLda(data = rice_train, class ~ .)
summary(rice_lda)
```

```{r lda_h2-check}
grade_code("Votre LDA est entrainé. Il faut encore mesuré ces performances.", "Avez vous bien proposé la formule écrites sous sa forme condensée ? ")
```

*La formule doit être écrite sous sa forme condensée*

Réalisez à présent votre modèle en utilisant la validation croisée.

```{r lda_cv_h2, exercise = TRUE}
set.seed(8888)
rice_lda_cv <- mlLda(data = ___, ___ ~ ___)
summary(rice_lda_cv)
```

```{r lda_cv_h2-hint-1}
set.seed(8888)
rice_lda_cv <- mlLda(data = rice, ___ ~ ___)
summary(rice_lda_cv)

## Attention, le prochain indice est la solution ##
```

```{r lda_cv_h2-solution}
## Solution ##
set.seed(8888)
rice_lda_cv <- mlLda(data = rice, class ~ .)
summary(rice_lda_cv)
```

```{r lda_cv_h2-check}
grade_code("Votre LDA avec validation croisée est entrainée. Il faut encore mesuré ces performances.", "Avez vous bien proposé la formule écrites sous sa forme condensée ?")
```

*La formule doit être écrite sous sa forme condensée*

## Évaluation des classifieurs

Vous avez réalisé deux classifieurs `rice_lda` et `rice_lda_cv`. Le premier n'utilise pas la validation croisée alors que le second l'utilise.

Les tableaux de données disponibles sont les suivants : `rice`, `rice_train`, `rice_test`

Évaluez les performances du premier classifieur `rice_lda`

```{r pred_lda_h2, exercise = TRUE}
# prédiction 
rice_pred <- ___(___, ___)
# matrice de confusion
rice_conf <- confusion(___, ___$___)
rice_conf
summary(rice_conf)
```

```{r pred_lda_h2-hint-1}
rice_pred <- predict(rice_lda, rice_test)
rice_conf <- confusion(rice_pred, ___$___)
rice_conf
summary(rice_conf)

## Attention, le prochain indice est la solution ##
```

```{r pred_lda_h2-solution}
## Solution ##
rice_pred <- predict(rice_lda, rice_test)
rice_conf <- confusion(rice_pred, rice_test$class)
rice_conf
summary(rice_conf)
```

```{r pred_lda_h2-check}
grade_code("Vous venez de calculer les métriques de performances du premier classifieur. Prenez un peu de temps pour analyser votre matrice de confusion et les métriques qui en découlent.")
```

Évaluez les performances du second classifieur `rice_lda_cv` à l'aide d'une validation croisée dix fois.

```{r lda_pred_cv_h2, exercise = TRUE}
set.seed(8888)
# prédiction 
rice_pred_cv <- ___(___, cv.k = ___)
# matrice de confusion
rice_conf_cv <- confusion(___, ___$___)
rice_conf_cv
summary(rice_conf_cv)
```

```{r lda_pred_cv_h2-hint-1}
set.seed(8888)
rice_pred_cv <- ___(rice_lda_cv, cv.k = ___)
rice_conf_cv <- confusion(rice_pred_cv, ___$___)
bio_conf_cv
summary(rice_conf_cv)

## Attention, le prochain indice est la solution ##
```

```{r lda_pred_cv_h2-solution}
## Solution ##
set.seed(8888)
rice_pred_cv <- cvpredict(rice_lda_cv, cv.k = 10)
rice_conf_cv <- confusion(rice_pred_cv, rice$class)
rice_conf_cv
summary(rice_conf_cv)
```

```{r lda_pred_cv_h2-check}
grade_code("Vous venez de réaliser les analyses des performances du second classifieur. Prenez un peu de temps pour analyser votre matrice de confusion et les métriques qui en découlent.")
```

Répondez aux questions ci-dessous. Ces questions portent sur l'évaluation des deux classifieurs.

```{r qu_lda_cv}
quiz(
  question("Quel classifieur permet d'avoir le taux d'erreur globale le plus bas ?",
    answer("L'analyse discriminante linéaire sans validation croisée"),
    answer("L'analyse discriminante linéaire avec validation croisée 10 fois", correct = TRUE),
    allow_retry = TRUE, 
    submit_button = "Soumettre une réponse",
    try_again_button = "Resoumettre une réponse",
    incorrect = "Mauvaise réponse. Recommencez afin de trouver la bonne réponse",
    correct = "Bravo, c'est correct !"),
  question("Combien d'items sont employé afin de déterminer les performances du classifieur avec validation croisée ?",
    answer(sprintf("%1.f", nrow(rice)), correct = TRUE),
    answer(sprintf("%1.f", nrow(rice_train))),
    answer(sprintf("%1.f", nrow(rice_test))),
    answer(sprintf("%1.f", sum(rice_tab_cv$TP))),
    allow_retry = TRUE, random_answer_order = TRUE,
    submit_button = "Soumettre une réponse",
    try_again_button = "Resoumettre une réponse",
    incorrect = "Mauvaise réponse. Recommencez afin de trouver la bonne réponse",
    correct = "Bravo, c'est correct ! On utilise l'ensemble des données disponibles."),
  question("Quel est le taux de vrai positif pour la classe `Osmancik` avec le classifieurs `rice_lda_cv` ?",
    answer(sprintf("%.3f", rice_tab_cv[row.names(rice_tab_cv) == "Osmancik", ]$Recall), correct = TRUE),
    answer(sprintf("%.3f", rice_tab_cv[row.names(rice_tab_cv) == "Osmancik", ]$Fscore)),
    answer(sprintf("%3.f", sum(rice_tab_cv$Auto) - sum(rice_tab_cv$TP))),
    answer(sprintf("%.3f", rice_tab_cv[row.names(rice_tab_cv) == "Cammeo", ]$Recall)),
    answer("Aucune des réponses proposées"),
    allow_retry = TRUE, random_answer_order = TRUE,
    submit_button = "Soumettre une réponse",
    try_again_button = "Resoumettre une réponse",
    incorrect = "Mauvaise réponse. Recommencez afin de trouver la bonne réponse",
    correct = "Bravo, c'est correct ! Vous avez analysé correctement les résulatats de votre analyse.")
  )
```

## Conclusion

Ce tutoriel vous a permis de découvrir la validation croisée appliquée sur une analyse discriminante linéaire. L'avantage de la validation croisée est de pouvoir employer plus de données pour entrainer votre classifieur.

```{r comm_noscore, echo=FALSE}
question_text(
  "Laissez-nous vos impressions sur cet outil pédagogique",
  answer("", TRUE, message = "Pas de commentaires... C'est bien aussi."),
  incorrect = "Vos commentaires sont enregistrés.",
  placeholder = "Entrez vos commentaires ici...",
  allow_retry = TRUE
)
```
