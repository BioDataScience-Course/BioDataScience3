---
title: "Validation croisée"
author: "Guyliann Engels & Philippe Grosjean"
description: "**SDD III Module 2** Utilisation de la validation croisée sur une ADL."
tutorial:
  id: "C02La_cv"
  version: 3.0.0/8
output:
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
BioDataScience3::learnr_setup()
SciViews::R("explore", "ml", lang = "fr")
# Required for RSConnect
# SciViews::R
library(rlang)
library(data.table)
library(ggplot2)
library(tibble)
library(tidyr)
library(dplyr)
library(dtplyr)
library(broom)
library(forcats)
library(collapse)
library(fs)
library(data.trame)
library(svFast)
library(svTidy)
library(svMisc)
library(svBase)
library(svFlow)
library(data.io)
library(chart)
library(tabularise)
library(SciViews)
# ... more
library(readxl)
library(testthat)
library(equatags)
# 'explore' and 'ml' packages
library(exploreit)
library(mlearning)
library(ROCR)
library(parsnip)
library(recipes)
library(rsample)
library(BioDataScience3)

# Import dataset
rice <- read("rice", package = "BioDataScience3", lang = "fr")
# Training and test set
set.seed(8888)
rice_split <- rsample::initial_split(rice, 0.8, strata = class)
rice_train <- rsample::training(rice_split)
rice_test <- rsample::testing(rice_split)
# mlLda
rice_lda <- mlLda(data = rice_train, class ~ .)
rice_conf <- confusion(predict(rice_lda, rice_test), rice_test$class)
rice_tab <- summary(rice_conf)
# mlda with 10-fold CV
rice_lda_cv <- mlLda(data = rice, class ~ .)
rice_conf_cv <- confusion(cvpredict(rice_lda_cv, cv.k = 10), rice$class)
rice_tab_cv <- summary(rice_conf_cv)
```

```{r, echo=FALSE}
BioDataScience3::learnr_banner()
```

```{r, context="server"}
if (Sys.info()["user"] == "rstudio-connect") {
  options(learnr_user_id = session$user)
  assignInNamespace("default_user_id", function() {
    getOption("learnr_user_id", unname(Sys.info()["user"]))
  }, ns = "learnr")
}
BioDataScience3::learnr_server(input, output, session)
```

------------------------------------------------------------------------

## Objectifs

Lors de la création d'un classifieur, nous allons définir un set d'apprentissage et un set de test. Il ne faut jamais employer les mêmes individus en apprentissage et en test. Cela aurait pour conséquence de surévaluer la capacité d'un classifieur à reconnaître les niveaux de la variable facteur d'intérêt.

La validation croisée est une méthode particulière qui permet d'utiliser tous les items, à la fois dans le set d'apprentissage et dans le set de test, mais jamais simultanément. Elle permet donc d'évaluer les performances d'un classifieur de manière non biaisée, tout en utilisant un maximum d'items à la fois en apprentissage et en test.

L'objectif de ce tutoriel est de comprendre la validation croisée et de l'appliquer en pratique dans le cas d'une analyse discriminante linéaire.

## Exploration des données

Les données employées dans cette séance d'exercices proviennent de l'article ["Classification of Rice Varieties Using Artificial Intelligence Methods"](https://doi.org/10.18201/ijisae.2019355381). N'hésitez pas à consulter cet article pour en apprendre davantage sur les données.

```{r, echo=TRUE}
rice <- read("rice", package = "BioDataScience3")
```

Le tableau `rice` a `r nrow(rice)` items. Deux variétés de riz sont étudiées : `Cammeo` et `Osmancik`. Sur base d'analyse d'image, sept variables morphométriques sont calculées sur base d'images numériques des grains de riz comme le périmètre, l'aire ou encore la longueur de l'axe majeur de l'ellipsoïde qui entoure la silhouette du grain de riz sur l'image.

Les tableaux ci-dessous résument les variables de notre jeu de données.

```{r, echo = TRUE}
skimr::skim(rice)
```

Nous avons une variable qualitative `class` à deux niveaux avec des effectifs relativement bien balancés entre les deux classes. Nous avons aussi sept variables numériques qui peuvent servir d'attributs dans une classification supervisée. Il n'y a aucune donnée manquante.

Vous utiliserez l'analyse discriminante linéaire pour entraîner vos classifieurs. Vous pouvez décrire vos données à l'aide de tableaux ou de graphiques supplémentaires. Vous pouvez aussi réaliser une ACP pour avoir une vue d'ensemble sur les données avant de vous lancer dans la classification ADL. Voici ce que cela donne :

```{r, echo=TRUE}
rice_pca <- pca(data = sselect(rice, -class), ~ ., scale = TRUE)
summary(rice_pca)
```

Le graphique des éboulis est présenté ci-dessous.

```{r, echo=TRUE}
chart$scree(rice_pca)
```

Voici la représentation dans l'espace des variables dans le premier plan de l'ACP :

```{r, echo=TRUE}
chart$loadings(rice_pca)
```

... et la représentation dans l'espace des individus, toujours dans le premier plan de l'ACP :

```{r, echo=TRUE}
chart$scores(rice_pca, labels = rice$class)
```

Notez bien qu'au niveau de l'ACP, la séparation entre les deux variétés de riz n'apparaît que très partielle.

## Préparation des sets d'apprentissage et de test

Utilisez les fonctions `initial_split()`, `training()` et `testing()` pour définir votre set d'apprentissage et votre set de test. Votre set d'apprentissage se nommera `rice_train` et votre set de test se nommera `rice_test`. Il vous est demandé de réaliser un set d'apprentissage contenant 80% des observations. Cet échantillonnage doit être stratifié pour la variable `class`.

```{r rice_split_h2, exercise=TRUE}
set.seed(8888) # Fixer le début du générateur de nombres pseudo-aléatoires
rice_split <- initial_split(___, prop = ___, strata = ___)
rice_split
# Diviser le tableau
___ <- training(___)
rice_test <- testing(___)
```

```{r rice_split_h2-hint-1}
set.seed(8888) # Fixer le début du générateur de nombres pseudo-aléatoires
rice_split <- initial_split(rice, prop = 0.8, strata = ___)
rice_split
# Diviser le tableau
___ <- training(___)
rice_test <- testing(___)

## Attention, le prochain indice est la solution ##
```

```{r rice_split_h2-solution}
set.seed(8888) # Fixer le début du générateur de nombres pseudo-aléatoires
rice_split <- initial_split(rice, prop = 0.8, strata = class)
rice_split
# Diviser le tableau
rice_train <- training(rice_split)
rice_test <- testing(rice_split)
```

```{r rice_split_h2-check}
grade_code("Vous avez réalisé votre set d'apprentissage et votre set de test avec les proportions demandées.", "Avez-vous bien respecté les consignes ? Il ne faut compléter que les champs ___.")
```

## Analyse discriminante linéaire

Entraînez un premier classifieur `rice_lda` avec l'analyse discriminante linéaire (formule condensée) pour prédire `class` à l'aide des sept autres variables **sans utiliser la validation croisée** ensuite. Quel jeu de données devez-vous utiliser ? `rice`, `rice_train` ou `rice_test` ?

```{r lda_h2, exercise=TRUE}
rice_lda <- ml_lda(data = ___, ___ ~ ___)
summary(rice_lda)
```

```{r lda_h2-hint-1}
rice_lda <- ml_lda(data = rice_train, ___ ~ ___)
summary(rice_lda)

## Attention, le prochain indice est la solution ##
```

```{r lda_h2-solution}
## Solution ##
rice_lda <- ml_lda(data = rice_train, class ~ .)
summary(rice_lda)
```

```{r lda_h2-check}
grade_code("Votre classifieur LDA est entrainé. Il faut encore en mesurer les performances.", "Avez-vous bien écrit la formule sous sa forme condensée ? Avez-vous choisi le bon jeu de données ?")
```

Entraînez maintenant un second classifieur `rice_lda_cv`, mais cette fois dans le but d'en étudier les performances par validation croisée (toujours en utilisant la formule condensée).

```{r lda_cv_h2, exercise=TRUE}
rice_lda_cv <- ml_lda(data = ___, ___ ~ ___)
summary(rice_lda_cv)
```

```{r lda_cv_h2-hint-1}
rice_lda_cv <- ml_lda(data = rice, ___ ~ ___)
summary(rice_lda_cv)

## Attention, le prochain indice est la solution ##
```

```{r lda_cv_h2-solution}
## Solution ##
rice_lda_cv <- ml_lda(data = rice, class ~ .)
summary(rice_lda_cv)
```

```{r lda_cv_h2-check}
grade_code("Si vous souhaitez utiliser la validation croisée pour le test, vous pouvez entraîner votre modèle sur l'ensemble des données dans un premier temps avec {mlearning} que nous utilisons ici. Il faut bien sûr encore étudier ses performances ensuite.", "Avez-vous bien écrit la formule sous sa forme condensée ?")
```

## Évaluation des performances des classifieurs

Évaluez les performances du premier classifieur `rice_lda` sans validation croisée. Pour rappel, les jeux de données disponibles sont les suivants : `rice`, `rice_train` et `rice_test`

```{r pred_lda_h2, exercise=TRUE}
# prédiction
rice_pred <- ___(___, ___)
# matrice de confusion
rice_conf <- confusion(___, ___$___)
rice_conf
summary(rice_conf)
```

```{r pred_lda_h2-hint-1}
rice_pred <- predict(rice_lda, rice_test)
rice_conf <- confusion(rice_pred, ___$___)
rice_conf
summary(rice_conf)

## Attention, le prochain indice est la solution ##
```

```{r pred_lda_h2-solution}
## Solution ##
rice_pred <- predict(rice_lda, rice_test)
rice_conf <- confusion(rice_pred, rice_test$class)
rice_conf
summary(rice_conf)
```

```{r pred_lda_h2-check}
grade_code("Vous venez de calculer les métriques de performances du premier classifieur. Prenez un peu de temps pour analyser votre matrice de confusion et les métriques qui en découlent. Combien de données sont utilisées ici ?")
```

Évaluez les performances du second classifieur `rice_lda_cv`, cette fois-ci, à l'aide d'une validation croisée dix fois.

```{r lda_pred_cv_h2, exercise=TRUE}
set.seed(76456)
# prédiction
rice_pred_cv <- ___(___, cv.k = ___)
# matrice de confusion
rice_conf_cv <- confusion(___, ___$___)
rice_conf_cv
summary(rice_conf_cv)
```

```{r lda_pred_cv_h2-hint-1}
set.seed(76456)
rice_pred_cv <- ___(rice_lda_cv, cv.k = ___)
rice_conf_cv <- confusion(rice_pred_cv, ___$___)
bio_conf_cv
summary(rice_conf_cv)

## Attention, le prochain indice est la solution ##
```

```{r lda_pred_cv_h2-solution}
## Solution ##
set.seed(76456)
rice_pred_cv <- cvpredict(rice_lda_cv, cv.k = 10)
rice_conf_cv <- confusion(rice_pred_cv, rice$class)
rice_conf_cv
summary(rice_conf_cv)
```

```{r lda_pred_cv_h2-check}
grade_code("Toute la mécanique de la validation croisée est déployée à l'intérieur de `cvpredict()`. En réalité, les données sont divisées en dix sous-tableaux et dix classifieurs différents sont entraînés et testés successivement. Aucun n'est identique à `rice_lda_cv`, mais ils en sont tous relativement proches. Prenez un peu de temps pour analyser votre matrice de confusion et les métriques qui en découlent. Combien de données sont utilisées ici ?")
```

Répondez aux questions ci-dessous relatives aux deux classifieurs `rice_lda` et `rice_lda_cv`.

```{r qu_lda_cv}
quiz(
  question("Quel classifieur permet d'avoir le taux d'erreur globale le plus bas ?",
    answer("L'analyse discriminante linéaire sans validation croisée"),
    answer("L'analyse discriminante linéaire avec validation croisée 10 fois", correct = TRUE),
    allow_retry = TRUE,
    submit_button = "Soumettre une réponse",
    try_again_button = "Resoumettre une réponse",
    incorrect = "Mauvaise réponse. Recommencez afin de trouver la bonne réponse",
    correct = "C'est le nombre d'observations utilisées en apprentissage qui sont déterminantes ici (plus d'observations mènent potentiellement à un meilleur classifieur)."),
  question("Combien d'items sont employés pour déterminer les performances du classifieur avec validation croisée ?",
    answer(sprintf("%1.f", nrow(rice)), correct = TRUE),
    answer(sprintf("%1.f", nrow(rice_train))),
    answer(sprintf("%1.f", nrow(rice_test))),
    answer(sprintf("%1.f", sum(rice_tab_cv$TP))),
    allow_retry = TRUE, random_answer_order = TRUE,
    submit_button = "Soumettre une réponse",
    try_again_button = "Resoumettre une réponse",
    incorrect = "Mauvaise réponse. Recommencez afin de trouver la bonne réponse",
    correct = "L'ensemble des données disponibles est en effet utilisé pour le test en validation croisée."),
  question("Quel est le taux de vrais positifs pour la classe `Osmancik` avec le classifieurs `rice_lda_cv` ?",
    answer(sprintf("%.3f", rice_tab_cv[row.names(rice_tab_cv) == "Osmancik", ]$Recall), correct = TRUE),
    answer(sprintf("%.3f", rice_tab_cv[row.names(rice_tab_cv) == "Osmancik", ]$Fscore)),
    answer(sprintf("%3.f", sum(rice_tab_cv$Auto) - sum(rice_tab_cv$TP))),
    answer(sprintf("%.3f", rice_tab_cv[row.names(rice_tab_cv) == "Cammeo", ]$Recall)),
    answer("Aucune des réponses proposées"),
    allow_retry = TRUE, random_answer_order = TRUE,
    submit_button = "Soumettre une réponse",
    try_again_button = "Resoumettre une réponse",
    incorrect = "Mauvaise réponse. Recommencez afin de trouver la bonne réponse",
    correct = "Vous avez analysé correctement les résultats obtenus.")
  )
```

Si nous revenons un instant sur l'analyse en composantes principales, nous n'avions observé qu'une séparation très faible des deux variétés de riz. L'analyse discriminante linéaire fait bien mieux. Bien que ces deux méthodes soient fortement apparentées et effectuent un calcul relativement similaire, leurs objectifs sont très différents. L'ACP **"étale" les points** au mieux dans le premier plan PC1 - PC2, alors que l'ADL **sépare les classes** au mieux dans le premier plan LD1 - LD2. Vous pouvez donc utiliser les résultats de votre ACP comme point de départ, mais vous ne pouvez pas conclure que la classification se fera bien ou pas sur cette base pour cette seule analyse.

## Conclusion

Ce tutoriel vous a permis de découvrir la validation croisée appliquée sur une analyse discriminante linéaire. L'avantage de la validation croisée est de pouvoir utiliser plus de données pour entraîner votre classifieur et également pour son test. Il n'est pas nécessaire de séparer les groupes à la main et de calculer *k* fois les performances avant de sommer les *k* matrices de confusion en une seule. La fonction `cvpredict()` se charge de faire tout cela pour vous automatiquement.

```{r comm_noscore, echo=FALSE}
question_text(
  "Laissez-nous vos impressions sur cet outil pédagogique",
  answer("", TRUE, message = "Pas de commentaires... C'est bien aussi."),
  incorrect = "Vos commentaires sont enregistrés.",
  placeholder = "Entrez vos commentaires ici...",
  allow_retry = TRUE
)
```

```{css, echo=FALSE}
@media print {
  .topics {
    width: 100% !important;
    padding: 0 0.5em 0 !important;
  }
  .topicsContainer, .topicsContainer *, .learnrBanner, .learnrBanner *, .topicActions, .topicActions * {
    display: none !important;
  }
}
```
