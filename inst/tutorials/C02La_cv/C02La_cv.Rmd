---
title: "Validation croisée"
author: "Guyliann Engels & Philippe Grosjean"
description: "**SDD III Module 2** Utilisation de la validation croisée sur une ADL."
tutorial:
  id: "C02La_cv"
  version: 2.0.0/5
output:
  learnr::tutorial:
    progressive: true
    allow_skip: true
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
BioDataScience3::learnr_setup()
SciViews::R()
library(mlearning)

read("biometry", package = "BioDataScience") %>.%
  select(., gender, weight, height, wrist) %>.%
  drop_na(.) %->%
  bio

bio_lda <- mlLda(data = bio, gender ~ .)

set.seed(634)
bio_conf <- confusion(cvpredict(bio_lda, cv.k = 10), bio$gender)
conf_tab <- summary(bio_conf)
```

```{r, echo=FALSE}
BioDataScience3::learnr_banner()
```

```{r, context="server"}
BioDataScience3::learnr_server(input, output, session)
```

------------------------------------------------------------------------

## Objectifs

-   Comprendre la validation croisée et l'appliquer en pratique dans le cas d'une analyse discriminante linéaire,

-   Ètre capable d'écrire le code en R poiur l'analyse précédente, en s'aidant du package {mlearning}.

## Création du classifieur

Vous avez à votre disposition le jeu de données `bio` dont un résumé est proposé ci-dessous.

```{r, echo = TRUE}
skimr::skim(bio)
```

Ce jeu de données contient `r ncol(bio)` variables. La variable `gender` est une variable facteur à deux niveaux : M (men), W (Women). De plus, trois variables numérique caractérisent les individus de l'échantillon :

-   weight : la masse en kg
-   height : la taille en cm
-   wrist : la circonférence du poignet en mm

Réalisez un classifieur en utilisant l"analyse discriminante linéaire (ADL) entraîné avec le jeu de données `bio` tout entier. Prédisez la variable `gender` à partir des trois variables numériques via la validation croisée dix fois. Commencez par créer votre objet `bio_lda`, et imprimez-en un résumé :

*Attention : la formule doit être écrite sous sa forme condensée.*

```{r lda1_h2, exercise = TRUE}
bio_lda <- mlLda(data = ___, ___ ~ ___)
summary(bio_lda)
```

```{r lda1_h2-hint-1}
bio_lda <- mlLda(data = bio, ___ ~ ___)
summary(bio_lda)

## Attention, le prochain indice est la solution ##
```

```{r lda1_h2-solution}
## Solution ##
bio_lda <- mlLda(data = bio, gender ~ .)
summary(bio_lda)
```

```{r lda1_h2-check}
grade_code("Votre modèle est entraîné, c'est la première étape... passons à la suite..")
```

## Performance du classifieur

Vous allez maintenant tester les performances de votre classifieur à l'aide d'une validation croisée dix fois.

```{r lda2_h2, exercise = TRUE}
set.seed(634)
bio_pred <- cvpredict(___, cv.k = ___)
bio_conf <- confusion(___, ___$___)
bio_conf
summary(bio_conf)
```

```{r lda2_h2-hint-1}
set.seed(634)
bio_pred <- cvpredict(bio_lda, cv.k = ___)
bio_conf <- confusion(bio_pred, bio$___)
bio_conf
summary(bio_conf)

## Attention, le prochain indice est la solution ##
```

```{r lda2_h2-solution}
## Solution ##
set.seed(634)
bio_pred <- cvpredict(bio_lda, cv.k = 10)
bio_conf <- confusion(bio_pred, bio$gender)
bio_conf
summary(bio_conf)
```

```{r lda2_h2-check}
grade_code("La fonction `cvpredict()` simplifie énormément le code, mais en interne, la validation croisée dix fois crée en réalité dix sets d'apprentissage et de test séparés. Ensuite, elle entraine `mlLda()` également dix fois et mesure la performance sur le set de test correspondant. Les dix résultats partiels sont joints dans la matrice de confusion finale (somme des effectifs partiels) pour obtenir le résultat final à l'aide de la fonction `confusion()`.")
```

Inspectez les résultats obtenus et répondez aux questions suivantes :

```{r lda_qu}
quiz(
  question("Combien d'items sont correctement classés ?",
    answer(sprintf("%1.f", sum(conf_tab$TP)), correct = TRUE),
    answer(sprintf("%1.f", sum(conf_tab$Auto))),
    answer(sprintf("%1.f", conf_tab$Manu[1])),
    answer(sprintf("%1.f", conf_tab$TN[2])),
    answer("Aucune des réponses proposées"),
    allow_retry = TRUE,
    incorrect = "Mauvaise réponse. Recommencez afin de trouver la bonne réponse",
    correct = "Bravo, c'est correct !"
    ),
  question("Quel est le taux d'erreur global (en %) ?",
    answer(sprintf("%.1f", 100 * (1 - (sum(conf_tab$TP) / sum(conf_tab$Auto)))), correct = TRUE),
    answer(sprintf("%.1f", 100 * (sum(conf_tab$TP) / sum(conf_tab$Auto)))),
  answer(sprintf("%3.f", sum(conf_tab$Auto) - sum(conf_tab$TP))),
    answer(sprintf("%3.f", conf_tab$TN[2])),
    answer("Aucune des réponses proposées"),
    allow_retry = TRUE,
    incorrect = "Mauvaise réponse. Recommencez afin de trouver la bonne réponse",
    correct = "Bravo, c'est correct !"
    ),
  question("Quel est la spécificité pour les femmes (W) ?",
    answer(sprintf("%.3f", conf_tab[row.names(conf_tab) == "W", ]$Specificity), correct = TRUE),
    answer(sprintf("%.3f", conf_tab[row.names(conf_tab) == "M", ]$Fscore)),
    answer(sprintf("%3.f", sum(conf_tab$Auto) - sum(conf_tab$TP))),
    answer(sprintf("%.3f", conf_tab[row.names(conf_tab) == "W", ]$Recall)),
    answer("Aucune des réponses proposées"),
    allow_retry = TRUE,
    incorrect = "Mauvaise réponse. Recommencez afin de trouver la bonne réponse",
    correct = "Bravo, c'est correct !"
    )
  )
```

## Conclusion

```{r comm_noscore, echo=FALSE}
question_text(
  "Laissez-nous vos impressions sur cet outil pédagogique",
  answer("", TRUE, message = "Pas de commentaires... C'est bien aussi."),
  incorrect = "Vos commentaires sont enregistrés.",
  placeholder = "Entrez vos commentaires ici...",
  allow_retry = TRUE
)
```
