---
title: "Courbes ROC"
author: "Guyliann Engels & Philippe Grosjean"
description: "**SDD III Module 3** Effet des proportions sur les métriques et courbes ROC."
tutorial:
  id: "C03La_roc"
version: 2.0.0/9
output:
  learnr::tutorial:
  progressive: true
allow_skip: true
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
BioDataScience3::learnr_setup()
SciViews::R()
library(mlearning)

# Importation des données
breast <- read("BreastCancer", package = "mlbench")
breast <- janitor::clean_names(breast)
breast <- na_omit(breast, "bare_nuclei")
breast <- sselect(breast, -id)

# Partitionnement récursif -------
## rpart1
set.seed(12)
breast_part <- mlRpart(data = breast, class~.)
breast_pred1 <- cvpredict(breast_part, cv.k = 5) 
part1_conf <- confusion(breast_pred1, breast$class)
part1_tab <- summary(part1_conf)

## rpart2
# sous ensemble des personnes malades
breast %>.%
  filter(., class == "malignant") %>.%
  sample_n(., 200) %->% br_m2
# sous ensemble des personnes saines
breast %>.%
  filter(., class == "benign") %>.%
  sample_n(., 50) %->% br_b2
# Combinaison des tableaux
breast2 %<-% bind_rows(br_m2, br_b2)
# Creation du model
breast_part2 <- mlRpart(data = breast2, class~.)
# Evaluation du model
breast_pred2 <- cvpredict(breast_part2, cv.k = 5) 
part2_conf <- confusion(breast_pred2, breast2$class)
part2_tab <- summary(part2_conf)

# Proba a priori
breast_prior <- table(breast$class) / nrow(breast)
breast_prior <- structure(as.numeric(breast_prior), names = names(breast_prior))
part2_conf2 <- part2_conf
prior(part2_conf2) <- breast_prior
part2_conf2_tab <- summary(part2_conf2)

#part1_tab
#part2_tab
#part2_conf2_tab

# ROC -----
set.seed(12)
breast_pred <- cvpredict(breast_part, cv.k = 5, type = "membership") 
#head(breast_pred)
```

```{r, echo=FALSE}
BioDataScience3::learnr_banner()
```

```{r, context="server"}
BioDataScience3::learnr_server(input, output, session)
```

------------------------------------------------------------------------

## Objectifs

Ce tutoriel doit encore être écrit. Vous devez probablement penser à installer une version plus récente du package qui contient les exercices finalisés !

Un classifieur qui ne commet pas d'erreur. Ce n'est pas réaliste (ou très très peu probable). Les métriques sont calculées sur base d'une matrice de confusion qui dénombre les vrais positifs, les faux positifs, les vrais négatifs et les faux négatifs. Ces métriques permettent d'évaluer la qualité d'un classifieur. Le nombre d'items dans chaque groupe de la variable à prédire va donc influencer ces métriques. Ce tutoriel s'intéresse tout d'abord à l'effet de proportions.

Un autre manière d'influencer notre classifueur va être de modifieur le seuil de détection. Etudier la variation du seuil de détection est l'objectif de la courbe ROC . Cette courbe représente le comportement de notre classifieur à deux classes pour tous les seuils de détection possibles.

## Effet des proportions sur les métriques

Lorsqu'un classifieur ne commet aucune erreur. Les proportions de chacune des classes n'ont aucune importance. Qu'il y ait 10, 1000, 10000 individus par classe n'aura aucun effet sur la qualité du classifieur que l'on détermine à l'aide des métriques. Par contre, dès qu'il y a des erreurs de classification, les proportions de chaque classe dans le set d'apprentissage vont avoir un effet dans les résultats de chaque métrique. Il peut être intéressant de modifier les proportions relatives de chaque classe afin de maximiser certaines métriques comme la précision ou le rappel. Cela va avoir généralement pour effet de réduire le taux de précision global.

Comme nous l'avons précisez depuis le premier module du cours de SDD III, il faut définir les métriques d'intérêt en fonction de la problématique que l'on étudie. Souhaite-t-on un classifieur qui commet globalement peu d'erreurs ou bien un classifieur très précis pour une classe particulière ? C'est à vous en tant qu'expert de le définir.

Vous avez à votre disposition le tableau `BreastCancer` du package {mlbench}. N'hésitez pas à consulter la page d'aide de ce tableau afin d'en apprendre davantage.

```{r, echo = TRUE}
breast <- read("BreastCancer", package = "mlbench")
breast <- janitor::clean_names(breast)
```

Ce tableau comprend `r nrow(breast)` individus et `r ncol(breast)`.

```{r, echo = TRUE}
skimr::skim(breast)
```

Quelques lignes du tableau de données sont éliminées afin de se débarrasser des valeurs manquantes dans le tableau. La variable `id` est également éliminée. Elle n'est pas utile dans notre analyse.

```{r, echo=TRUE}
# élimination des valeurs manquantes.
breast <- na_omit(breast, "bare_nuclei")
# Suppression de la colonne id
breast <- sselect(breast, -id)
```

La répartition entre les patients atteints d'une tumeur bénigne et maligne n'est pas homogène dans ce tableau.

```{r}
table(breast$class)
```

Les médecins font appel à vous afin de mettre en place un classifieur capable de trouver un maximum de personne atteint d'une tumeur maligne.

Ils acceptent que le classifieur se trompe et prédisent des faux positifs. Par contre, ils ne souhaitent pas rater de patients malades.

Réalisez un premier classifieur utilisant le partitionnement récursif et la validation croisée 5 fois afin d'employer un maximum d'observations. Nommez ce classifieur `breast_part`.

```{r rpart1_h2, exercise = TRUE}
set.seed(12)
# Création du classifieur
breast_part <- ml___(data = ___, ___~___)
# Evaluation du classifieur
cvpredict(___, cv.k = ___)|> confusion(___$___) |> summary()
```

```{r rpart1_h2-hint-1}
set.seed(12)
# Création du classifieur
breast_part <- mlRpart(data = breast, class~.)
# Evaluation du classifieur
cvpredict(___, cv.k = ___)|> confusion(___$___) |> summary()

## Attention, le prochain indice est la solution ##
```

```{r rpart1_h2-solution}
set.seed(12)
# Création du classifieur
breast_part <- mlRpart(data = breast, class~.)
# Evaluation du classifieur
cvpredict(breast_part, cv.k = 5)|> confusion(breast$class) |> summary()
```

```{r rpart1_h2-check}
grade_code("Bien joué ! Vous avez réalisé et évalué votre classifieur.")
```

```{r qu_rpart}
question("Quel est la valeur de taux de vrais positifs pour les personnes malades ?",
  answer(sprintf("%.4f", part1_tab["malignant",]$Recall), correct = TRUE),
  answer(sprintf("%.4f", part1_tab["malignant",]$Specificity)),
  answer(sprintf("%.4f", part1_tab["malignant",]$LRPT)),
  answer(sprintf("%.4f", part1_tab["malignant",]$FDR)),
  allow_retry = TRUE, 
  submit_button = "Soumettre une réponse",
  try_again_button = "Resoumettre une réponse",
  incorrect = "Mauvaise réponse. Recommencez et analysez plus finement les métriques associés à ce classifieur.",
  correct = "Bravo, c'est correct !")
```

À présent, proposez un nouveau classifieur utilisant à nouveau le partitionnement récursif avec une validation croisée 5 fois. Modifiez le set d'apprentissage afin d'avoir 200 patients malades et 100 patients sains.

```{r split_h2, exercise = TRUE}
set.seed(12)
# sous ensemble des personnes malades
breast %>.%
  filter(., ___ == ___) %>.%
  sample_n(., ___) %->% br_m2
# sous ensemble des personnes saines
breast %>.%
  filter(., ___ == ___) %>.%
  sample_n(., ___) %->% br_b2
# Combinaison des tableaux
breast2 %<-% bind_rows(___, ___)
table(breast2$class)
```

```{r split_h2-hint-1}
set.seed(12)
# sous ensemble des personnes malades
breast %>.%
  filter(., class == ___) %>.%
  sample_n(., ___) %->% br_m2
# sous ensemble des personnes saines
breast %>.%
  filter(., class == ___) %>.%
  sample_n(., ___) %->% br_b2
# Combinaison des tableaux
breast2 %<-% bind_rows(br_m2, br_b2)
table(breast2$class)

## Attention, le prochain indice est la solution ##
```

```{r split_h2-solution}
set.seed(12)
# sous ensemble des personnes malades
breast %>.%
  filter(., class == "malignant") %>.%
  sample_n(., 200) %->% br_m2
# sous ensemble des personnes saines
breast %>.%
  filter(., class == "benign") %>.%
  sample_n(., 100) %->% br_b2
# Combinaison des tableaux
breast2 %<-% bind_rows(br_m2, br_b2)
table(breast2$class)
```

```{r split_h2-check}
grade_code("Bien joué ! Vous avez divisé en deux sous ensembles puis vous avez recombiné ces sous ensembles.")
```

Calculez le second classifieur.

```{r rpart2_h2, exercise = TRUE}
set.seed(12)
breast_part2 <- ml___(data = ___, ___~___)
cvpredict(breast_part2, cv.k = ___) |> confusion(___$___) ->
  part2_conf
summary(part2_conf) 
```

```{r rpart2_h2-hint-1}
set.seed(12)
breast_part2 <- mlRpart(data = breast2, class~.)
cvpredict(breast_part2, cv.k = ___) |> confusion(___$___) ->
  part2_conf
summary(part2_conf) 

## Attention, le prochain indice est la solution ##
```

```{r rpart2_h2-solution}
set.seed(12)
breast_part2 <- mlRpart(data = breast2, class~.)
cvpredict(breast_part2, cv.k = 5) |> confusion(breast2$class) ->
  part2_conf
summary(part2_conf) 
```

```{r rpart2_h2-check}
grade_code("Bravo ! Vous venez de réalsier et d'évaluer le second classifieur.")
```

Définissez les probabilités *a priori* et corrigez la matrice de confusion. Vous avez calculé la matrice de confusion précédemment et l'avez nommée `part2_conf`.

```{r prior_h2, exercise = TRUE}
# Calcul des probabilités a priori
breast_prior <- table(___$___) / nrow(___)
breast_prior <- structure(as.numeric(breast_prior), names = names(breast_prior))
breast_prior
# Adaptation de la matrice de confusion
prior(___) <- breast_prior
summary(___)
```

```{r prior_h2-hint-1}
# Calcul des probabilités a priori
breast_prior <- table(breast$class) / nrow(___)
breast_prior <- structure(as.numeric(breast_prior), names = names(breast_prior))
breast_prior
# Adaptation de la matrice de confusion
prior(___) <- breast_prior
summary(___)

## Attention, le prochain indice est la solution ##
```

```{r prior_h2-solution}
# Calcul des probabilités a priori
breast_prior <- table(breast$class) / nrow(breast)
breast_prior <- structure(as.numeric(breast_prior), names = names(breast_prior))
breast_prior
# Adaptation de la matrice de confusion
prior(part2_conf) <- breast_prior
summary(part2_conf)
```

```{r prior_h2-check}
grade_code("Bien joué ! Vous avez su adapter vos métriques en tenant compte des probabilités a priori. Répondez à la question suivante. ")
```

```{r qu_rpart2}
quiz(
  question("Quelle est la précision du second classifieur afin de détecter les personnes malades ?",
    answer(sprintf("%.4f", part2_conf2_tab["malignant",]$Precision), correct = TRUE),
    answer(sprintf("%.4f", part2_tab["malignant",]$Precision)),
    answer(sprintf("%.4f", part1_tab["malignant",]$Precision)),
    answer(sprintf("%.4f", part2_conf2_tab["benign",]$Precision)),
    allow_retry = TRUE, 
    submit_button = "Soumettre une réponse",
    try_again_button = "Resoumettre une réponse",
    incorrect = "Mauvaise réponse. Recommencez et analysez plus finement les métriques associés aux classifieurs.",
    correct = "Bravo, c'est correct !"),
  question("Quel est la valeur de taux de vrais positifs pour les personnes malades ?",
    answer(sprintf("%.4f", part2_conf2_tab["malignant",]$Recall), correct = TRUE),
    answer(sprintf("%.4f", part2_tab["malignant",]$Specificity)),
    answer(sprintf("%.4f", part1_tab["malignant",]$Fscore)),
    answer(sprintf("%.4f", part2_conf2_tab["malignant",]$FDR)),
    allow_retry = TRUE, 
    submit_button = "Soumettre une réponse",
    try_again_button = "Resoumettre une réponse",
    incorrect = "Mauvaise réponse. Recommencez et analysez plus finement les métriques associés aux classifieurs.",
    correct = "Bravo, c'est correct ! Vous pouvez observer que la modification des proportions a permis d'augmenter grandement le taux de vrais positifs. Cependant, nous observons une perte de précision. Les médecins vont préférer détecter un maximum de personnes malades avec quelques faux positifs.")
)
```

## courbes ROC

Dans la section précédente, nous avons employé les proportions relatives afin de modifier les performances de notre classifieur (rappel VS précision). Il est possible de modifier le seuil de détection. La courbe ROC permet d'étudier tous les seuils de détection pour un classifieur à deux classes.

Outre la variation des proportions relatives des individus dans le set d'apprentissage, nous pouvons aussi faire varier les performances de notre classifieur entre rappel et précision en modifiant le seuil de détection.

```{r, echo=TRUE}
set.seed(12)
breast_pred <- cvpredict(breast_part, cv.k = 5, type = "membership") 
head(breast_pred)
```

Réalisez en R de base le graphique de la courbe ROC. Vous devez commencer par formater les prédictions pour ROCR et nommer cet objet `pred_obj`. Ensuite, vous devez calculer les performances de votre `pred_obj` et le nommer `perf`. Déterminer les taux de vrais positifs (`tpr`) et le taux de faux positifs (`fpr`).

```{r roc_h2, exercise = TRUE}
library(ROCR)
# 1) Formater les prédictions pour ROCR
___ <- prediction(breast_pred[,"malignant"], breast$class == "malignant")
# 2) Calculer les performances avec les 2 métriques tpr et fpr
___<- performance(___, ___, ___)
# 3) Tracer le graphique ROC
plot(___)
abline(a = 0, b = 1, lty = 2)
```

```{r roc_h2-hint-1}
library(ROCR)
# 1) Formater les prédictions pour ROCR
___ <- prediction(breast_pred[,"malignant"], breast$class == "malignant")
# 2) Calculer les performances avec les 2 métriques tpr et fpr
___<- performance(___, "tpr", "fpr")
# 3) Tracer le graphique ROC
plot(___)
abline(a = 0, b = 1, lty = 2)
```

```{r roc_h2-solution}
library(ROCR)
# 1) Formater les prédictions pour ROCR
pred_obj <- prediction(breast_pred[,"malignant"], breast$class == "malignant")
# 2) Calculer les performances avec les 2 métriques tpr et fpr
perf <- performance(pred_obj, "tpr", "fpr")
# 3) Tracer le graphique ROC
plot(perf)
abline(a = 0, b = 1, lty = 2)
```

```{r roc_h2-check}
grade_code("Bravo ! Vous avez obtenu le graphique souhaité. On observe que le taux de vrais positifs augmente très rapidement.")
```

Déterminez l'aire sous la courbe à l'aide de la fonction `auc()` du package {pROC}. Employez l'objet `breast_pred` explicité ci-dessus.

```{r auc_h2, exercise = TRUE}
___::___(___$___, ___[, "malignant"])
```

```{r auc_h2-hint-1}
___::auc(___$___, ___[, "malignant"])
```

```{r auc_h2-solution}
pROC::auc(breast$class, breast_pred[, "malignant"])
```

```{r auc_h2-check}
grade_code("Bien joué ! Vous avez déterminé la valeur de l'aire sous la courbe ROC.")
```

## Conclusion

Bien joué ! Vous venez de découvrir l'effet des proportions sur le set d'apprentissage et la courbe ROC. Votre boite à outils s'étoffe de module en module. En plus de choisir un modèle pour votre classifieur, vous apprenez à l'optimiser.

```{r comm_noscore, echo=FALSE}
question_text(
  "Laissez-nous vos impressions sur cet outil pédagogique",
  answer("", TRUE, message = "Pas de commentaires... C'est bien aussi."),
  incorrect = "Vos commentaires sont enregistrés.",
  placeholder = "Entrez vos commentaires ici...",
  allow_retry = TRUE
)
```
