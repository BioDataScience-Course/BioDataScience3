---
title: "Machine learning (2)"
author: "Guyliann Engels & Philippe Grosjean"
description: "**SDD III Module 2** K plus proches voisins, méthodes par arbres, forêt aléatoire."
tutorial:
  id: "C02Lb_ml2"
version: 2.0.0/6
output:
  learnr::tutorial:
  progressive: true
allow_skip: true
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
BioDataScience3::learnr_setup()
SciViews::R()
library(mlearning)

# Import dataset ----
pumpkins <- read("pumpkins", package = "BioDataScience3")

library(rsample)
set.seed(101121) # Générateur de nombres pseudo-aléatoires
pumpkins_split <- initial_split(pumpkins, prop = 0.8)
pumpkins_split
# training set
pumpkins_train <- training(pumpkins_split)
# test set
pumpkins_test <- testing(pumpkins_split)

# Classifieurs 
## K plus proches voisins
pumpkins_knn <- mlKnn(data = pumpkins_train, class~., k.nn = 15)
## Partitionnement récursif
pumpkins_part <- mlRpart(data = pumpkins_train, class~.)
## Forêt aléatoire
pumpkins_rf <- mlRforest(data = pumpkins_train, class~., ntree = 100)

# Matrice de confusion
## K plus proches voisins
predict(pumpkins_knn, pumpkins_test) |> confusion(pumpkins_test$class) |> summary() ->
  conf_knn
## Partitionnement récursif
predict(pumpkins_part, pumpkins_test) |> confusion(pumpkins_test$class) |> summary() -> 
  conf_part
## forêt aléatoire
predict(pumpkins_rf, pumpkins_test) |> confusion(pumpkins_test$class) |> summary() ->
  conf_rf
```

```{r, echo=FALSE}
BioDataScience3::learnr_banner()
```

```{r, context="server"}
BioDataScience3::learnr_server(input, output, session)
```

------------------------------------------------------------------------

## Objectifs

Ce tutoriel a pour objectif de vous permettre de découvrir de nouveaux algorithmes de classifications supervisées. Il s'intéresse aux K plus proches voisins, à la méthode par arbres et à la méthode par de la forêt aléatoire.

Ces trois méthodes vont s'ajouter à l'analyse discriminante linéaire que vous avez découverte dans le premier module du cours de SDD III. Toutes ces méthodes font partie de votre boite à outils de la classification supervisée. Employez la méthode la plus judicieuse en fonction du contexte. Il est même conseillé de les tester et de les comparer afin de proposer le classifieur le plus efficace.

Lors du premier module, vous avez employé la fonction mlLda() afin de réaliser une analyse discriminante linéaire. Voici les nouvelles fonctions proposées par le package {mlearning}

| **Méthode**                    | **Fonction**                 |
|--------------------------------|------------------------------|
| Analyse discriminante linéaire | mlLda(data, formula,...)     |
| K plus proches voisins         | mlKnn(data, formula,...)     |
| Partitionnement récursif       | mlRpart(data, formula,...)   |
| Foret aléatoire                | mlRforest(data, formula,...) |

Le package {mlearning} permet d'utiliser une interface similaire pour chaque méthode.

## Explorer les données

Les données employées dans ce tutoriel sont associées à l'article : ["Classification of Rice Varieties Using Artificial Intelligence Methods"](https://doi.org/10.18201/ijisae.2019355381). N'hésitez pas à consulter cet article pour en apprendre davantage sur ces données.

```{r, echo = TRUE}
pumpkins <- read("pumpkins", package = "BioDataScience3")
```

Ce tableau de données traite de la différenciation de deux variétés de graines de courge. Il comprend `r nrow(pumpkins)` observations et `r ncol(pumpkins)` variables. Les douze premières variables sont des attributs morphologiques obtenus par analyse d'image et la dernière colonne correspond à la classe. Cette variable facteur est à 2 niveaux.

```{r}
skimr::skim(pumpkins)
```

C'est à vous d'explorer ce tableau. Vous avez la possibilité de réaliser tous les analyses et graphiques que vous désirez.

```{r explo_noscor, exercise=TRUE}

```

## Préparer le set d'apprentissage et le test

Réalisez le set d'apprentissage et le set de test. 80% des observations vont servir à entrainer le classifieur et 20% pour évaluer le classifieur. Le tableau de données se nomme `pumpkins`. Utilisez les fonctions dédiées à la création des sets d'apprentissage et de test `initial_spit()`, `training()`, `testing()` du package {rsample}.

```{r split_h2, exercise = TRUE}
library(rsample)
set.seed(101121) # Générateur de nombres pseudo-aléatoires
pumpkins_split <- initial_split(___, prop = ___)
pumpkins_split
# training set
pumpkins_train <- ___(___)
# test set
pumpkins_test <- ___(___)
```

```{r split_h2-hint-1}
library(rsample)
set.seed(101121) # Générateur de nombres pseudo-aléatoires
pumpkins_split <- initial_split(___, prop = ___)
pumpkins_split
# training set
pumpkins_train <- training(pumpkins_split)
# test set
pumpkins_test <- ___(___)

## Attention, le prochain indice est la solution ##
```

```{r split_h2-solution}
library(rsample)
set.seed(101121) # Générateur de nombres pseudo-aléatoires
pumpkins_split <- initial_split(pumpkins, prop = 0.8)
pumpkins_split
# training set
pumpkins_train <- training(pumpkins_split)
# test set
pumpkins_test <- testing(pumpkins_split)
```

```{r split_h2-check}
grade_code("Bien joué ! La création d'un set d'apprentissage et d'un set de test n'a plus de secret pour vous.")
```

## Entrainement des classifieurs

Créez trois classifieurs. Le premier classifieur doit employer la méthode des K plus proches voisins avec 15 individus proches considérés (`k.nn=`). Le second classifieur doit employer le partitionnement récursif. Le troisième doit utiliser la forêt aléatoire avec un nombre d'arbres limité à 100 (`ntree=`). Utilisez le set d'apprentissage préparé à l'étape précédente.

```{r ml_h2, exercise = TRUE}
# K plus proches voisins
pumpkins_knn <- ml___(data = ___, ___~___, ___ = ___)
# Partitionnement récursif
pumpkins_part <- ml___(data = ___, ___~___)
# Forêt aléatoire
pumpkins_rf <- ml___(data = ___, ___~___, ___ = ___)
```

```{r ml_h2-hint-1}
# K plus proches voisins
pumpkins_knn <- mlKnn(data = pumpkins_train, class~., k.nn = 15)
# Partitionnement récursif
pumpkins_part <- mlRpart(data = pumpkins_train, class~.)
# Forêt aléatoire
pumpkins_rf <- mlRforest(data = pumpkins_train, class~., ntree = 100)

## Attention, le prochain indice est la solution ##
```

```{r ml_h2-solution}
# K plus proches voisins
pumpkins_knn <- mlKnn(data = pumpkins_train, class~., k.nn = 15)
# Partitionnement récursif
pumpkins_part <- mlRpart(data = pumpkins_train, class~.)
# Forêt aléatoire
pumpkins_rf <- mlRforest(data = pumpkins_train, class~., ntree = 100)
```

```{r ml_h2-check}
grade_code("Bravo ! Vous avez les trois classifieurs avec les arguments demandés. Passons à l'analyse des performances via les métriques.")
```

## Évaluation des classifieurs

Évaluez la qualité des trois classifieurs pumpkins_knn, pumpkins_part, pumpkins-rf. Définissez le tableau de données à employer entre `pumpkins`, `pumpkins_train` et `pumpkins_test`.

```{r predict_h2, exercise = TRUE}
# K plus proches voisins
predict(___, ___) |> confusion(___$___) |> summary()
# Partitionnement récursif
predict(___, ___) |> confusion(___$___) |> summary()
# forêt aléatoire
predict(___, ___) |> confusion(___$___) |> summary()
```

```{r predict_h2-hint-1}
# K plus proches voisins
predict(pumpkins_knn, pumpkins_test) |> confusion(___$class) |> summary()
# Partitionnement récursif
predict(___, ___) |> confusion(___$___) |> summary()
# forêt aléatoire
predict(___, ____) |> confusion(___$___) |> summary()

## Attention, le prochain indice est la solution ##
```

```{r predict_h2-solution}
# K plus proches voisins
predict(pumpkins_knn, pumpkins_test) |> confusion(pumpkins_test$class) |> summary()
# Partitionnement récursif
predict(pumpkins_part, pumpkins_test) |> confusion(pumpkins_test$class) |> summary()
# forêt aléatoire
predict(pumpkins_rf, pumpkins_test) |> confusion(pumpkins_test$class) |> summary()
```

```{r predict_h2-check}
grade_code("Bien joué ! Vous avez calculé les métriques des trois modèles. Vous maitrisez en plus l'utilisation du pipe natif de R.")
```

*Le pipe natif est employé dans cet exercice*

```{r qu_algo}
quiz(
  question("Quel classifieur permet d'avoir le meilleur taux de reconnaissance global ?",
    answer("Les K plus proches voisins"),
    answer("Le partitionnement récursif"),
    answer("La forêt aléatoire", correct = TRUE),
    allow_retry = TRUE, 
    submit_button = "Soumettre une réponse",
    try_again_button = "Resoumettre une réponse",
    incorrect = "Mauvaise réponse. Recommencez et analysez les métriques des trois classifieurs.",
    correct = "Bravo, c'est correct !"),
  question("Quel est la valeur du taux de vrais positifs pour le groupe des Cercevelik obtenu via le classifieur utilisant les k plus proches voisins ?",
    answer(sprintf("%.4f", conf_knn["Cercevelik",]$Recall), correct = TRUE),
    answer(sprintf("%.4f", conf_knn["Cercevelik",]$Precision)),
    answer(sprintf("%.4f", conf_knn["Cercevelik",]$Fscore)),
    answer(sprintf("%.4f", conf_knn["Cercevelik",]$FDR)),
    allow_retry = TRUE, 
    submit_button = "Soumettre une réponse",
    try_again_button = "Resoumettre une réponse",
    incorrect = "Mauvaise réponse. Recommencez et analysez plus finement les métriques associés à ce classifieur.",
    correct = "Bravo, c'est correct !"),
  question("Quel est la valeur de spécificité pour le groupe des Urgup Sivrisi obtenu via le classifieur utilisant la forêt aléatoire ?",
    answer(sprintf("%.4f", conf_rf["Urgup Sivrisi",]$Specificity), correct = TRUE),
    answer(sprintf("%.4f", conf_rf["Urgup Sivrisi",]$Precision)),
    answer(sprintf("%.4f", conf_rf["Urgup Sivrisi",]$Fscore)),
    answer(sprintf("%.4f", conf_rf["Urgup Sivrisi",]$FDR)),
    allow_retry = TRUE, 
    submit_button = "Soumettre une réponse",
    try_again_button = "Resoumettre une réponse",
    incorrect = "Mauvaise réponse. Recommencez et analysez plus finement les métriques associés à ce classifieur.",
    correct = "Bravo, c'est correct !")
  )
```

## Conclusion

Bien joué ! Vous venez de découvrir 3 nouveaux algorithmes de classifications supervisées. Votre boite à outils s'étoffe de modules en modules.

```{r comm_noscore, echo=FALSE}
question_text(
  "Laissez-nous vos impressions sur cet outil pédagogique",
  answer("", TRUE, message = "Pas de commentaires... C'est bien aussi."),
  incorrect = "Vos commentaires sont enregistrés.",
  placeholder = "Entrez vos commentaires ici...",
  allow_retry = TRUE
)
```
